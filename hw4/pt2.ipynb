{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXcACvbrElHTVPqvdB1kOi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Scaglione-Nick/ECGR4106/blob/main/pt2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_to_french = [\n",
        "\n",
        "    (\"I am cold\", \"J'ai froid\"),\n",
        "    (\"You are tired\", \"Tu es fatigué\"),\n",
        "    (\"He is hungry\", \"Il a faim\"),\n",
        "    (\"She is happy\", \"Elle est heureuse\"),\n",
        "    (\"We are friends\", \"Nous sommes amis\"),\n",
        "    (\"They are students\", \"Ils sont étudiants\"),\n",
        "    (\"The cat is sleeping\", \"Le chat dort\"),\n",
        "    (\"The sun is shining\", \"Le soleil brille\"),\n",
        "    (\"We love music\", \"Nous aimons la musique\"),\n",
        "    (\"She speaks French fluently\", \"Elle parle français couramment\"),\n",
        "    (\"He enjoys reading books\", \"Il aime lire des livres\"),\n",
        "    (\"They play soccer every weekend\", \"Ils jouent au football chaque week-end\"),\n",
        "    (\"The movie starts at 7 PM\", \"Le film commence à 19 heures\"),\n",
        "    (\"She wears a red dress\", \"Elle porte une robe rouge\"),\n",
        "    (\"We cook dinner together\", \"Nous cuisinons le dîner ensemble\"),\n",
        "    (\"He drives a blue car\", \"Il conduit une voiture bleue\"),\n",
        "    (\"They visit museums often\", \"Ils visitent souvent des musées\"),\n",
        "    (\"The restaurant serves delicious food\", \"Le restaurant sert une délicieuse cuisine\"),\n",
        "    (\"She studies mathematics at university\", \"Elle étudie les mathématiques à l'université\"),\n",
        "    (\"We watch movies on Fridays\", \"Nous regardons des films le vendredi\"),\n",
        "    (\"He listens to music while jogging\", \"Il écoute de la musique en faisant du jogging\"),\n",
        "    (\"They travel around the world\", \"Ils voyagent autour du monde\"),\n",
        "    (\"The book is on the table\", \"Le livre est sur la table\"),\n",
        "    (\"She dances gracefully\", \"Elle danse avec grâce\"),\n",
        "    (\"We celebrate birthdays with cake\", \"Nous célébrons les anniversaires avec un gâteau\"),\n",
        "    (\"He works hard every day\", \"Il travaille dur tous les jours\"),\n",
        "    (\"They speak different languages\", \"Ils parlent différentes langues\"),\n",
        "    (\"The flowers bloom in spring\", \"Les fleurs fleurissent au printemps\"),\n",
        "    (\"She writes poetry in her free time\", \"Elle écrit de la poésie pendant son temps libre\"),\n",
        "    (\"We learn something new every day\", \"Nous apprenons quelque chose de nouveau chaque jour\"),\n",
        "    (\"The dog barks loudly\", \"Le chien aboie bruyamment\"),\n",
        "    (\"He sings beautifully\", \"Il chante magnifiquement\"),\n",
        "    (\"They swim in the pool\", \"Ils nagent dans la piscine\"),\n",
        "    (\"The birds chirp in the morning\", \"Les oiseaux gazouillent le matin\"),\n",
        "    (\"She teaches English at school\", \"Elle enseigne l'anglais à l'école\"),\n",
        "    (\"We eat breakfast together\", \"Nous prenons le petit déjeuner ensemble\"),\n",
        "    (\"He paints landscapes\", \"Il peint des paysages\"),\n",
        "    (\"They laugh at the joke\", \"Ils rient de la blague\"),\n",
        "    (\"The clock ticks loudly\", \"L'horloge tic-tac bruyamment\"),\n",
        "    (\"She runs in the park\", \"Elle court dans le parc\"),\n",
        "    (\"We travel by train\", \"Nous voyageons en train\"),\n",
        "    (\"He writes a letter\", \"Il écrit une lettre\"),\n",
        "    (\"They read books at the library\", \"Ils lisent des livres à la bibliothèque\"),\n",
        "    (\"The baby cries\", \"Le bébé pleure\"),\n",
        "    (\"She studies hard for exams\", \"Elle étudie dur pour les examens\"),\n",
        "    (\"We plant flowers in the garden\", \"Nous plantons des fleurs dans le jardin\"),\n",
        "    (\"He fixes the car\", \"Il répare la voiture\"),\n",
        "    (\"They drink coffee in the morning\", \"Ils boivent du café le matin\"),\n",
        "    (\"The sun sets in the evening\", \"Le soleil se couche le soir\"),\n",
        "    (\"She dances at the party\", \"Elle danse à la fête\"),\n",
        "    (\"We play music at the concert\", \"Nous jouons de la musique au concert\"),\n",
        "    (\"He cooks dinner for his family\", \"Il cuisine le dîner pour sa famille\"),\n",
        "    (\"They study French grammar\", \"Ils étudient la grammaire française\"),\n",
        "    (\"The rain falls gently\", \"La pluie tombe doucement\"),\n",
        "    (\"She sings a song\", \"Elle chante une chanson\"),\n",
        "    (\"We watch a movie together\", \"Nous regardons un film ensemble\"),\n",
        "    (\"He sleeps deeply\", \"Il dort profondément\"),\n",
        "    (\"They travel to Paris\", \"Ils voyagent à Paris\"),\n",
        "    (\"The children play in the park\", \"Les enfants jouent dans le parc\"),\n",
        "    (\"She walks along the beach\", \"Elle se promène le long de la plage\"),\n",
        "    (\"We talk on the phone\", \"Nous parlons au téléphone\"),\n",
        "    (\"He waits for the bus\", \"Il attend le bus\"),\n",
        "    (\"They visit the Eiffel Tower\", \"Ils visitent la tour Eiffel\"),\n",
        "    (\"The stars twinkle at night\", \"Les étoiles scintillent la nuit\"),\n",
        "    (\"She dreams of flying\", \"Elle rêve de voler\"),\n",
        "    (\"We work in the office\", \"Nous travaillons au bureau\"),\n",
        "    (\"He studies history\", \"Il étudie l'histoire\"),\n",
        "    (\"They listen to the radio\", \"Ils écoutent la radio\"),\n",
        "    (\"The wind blows gently\", \"Le vent souffle doucement\"),\n",
        "    (\"She swims in the ocean\", \"Elle nage dans l'océan\"),\n",
        "    (\"We dance at the wedding\", \"Nous dansons au mariage\"),\n",
        "    (\"He climbs the mountain\", \"Il gravit la montagne\"),\n",
        "    (\"They hike in the forest\", \"Ils font de la randonnée dans la forêt\"),\n",
        "    (\"The cat meows loudly\", \"Le chat miaule bruyamment\"),\n",
        "    (\"She paints a picture\", \"Elle peint un tableau\"),\n",
        "    (\"We build a sandcastle\", \"Nous construisons un château de sable\"),\n",
        "    (\"He sings in the choir\", \"Il chante dans le chœur\"),\n",
        "    (\"They ride bicycles\", \"Ils font du vélo\"),\n",
        "    (\"The coffee is hot\", \"Le café est chaud\"),\n",
        "    (\"She wears glasses\", \"Elle porte des lunettes\"),\n",
        "    (\"We visit our grandparents\", \"Nous rendons visite à nos grands-parents\"),\n",
        "    (\"He plays the guitar\", \"Il joue de la guitare\"),\n",
        "    (\"They go shopping\", \"Ils font du shopping\"),\n",
        "    (\"The teacher explains the lesson\", \"Le professeur explique la leçon\"),\n",
        "    (\"She takes the train to work\", \"Elle prend le train pour aller au travail\"),\n",
        "    (\"We bake cookies\", \"Nous faisons des biscuits\"),\n",
        "    (\"He washes his hands\", \"Il se lave les mains\"),\n",
        "    (\"They enjoy the sunset\", \"Ils apprécient le coucher du soleil\"),\n",
        "    (\"The river flows calmly\", \"La rivière coule calmement\"),\n",
        "    (\"She feeds the cat\", \"Elle nourrit le chat\"),\n",
        "    (\"We visit the museum\", \"Nous visitons le musée\"),\n",
        "    (\"He fixes his bicycle\", \"Il répare son vélo\"),\n",
        "    (\"They paint the walls\", \"Ils peignent les murs\"),\n",
        "    (\"The baby sleeps peacefully\", \"Le bébé dort paisiblement\"),\n",
        "    (\"She ties her shoelaces\", \"Elle attache ses lacets\"),\n",
        "    (\"We climb the stairs\", \"Nous montons les escaliers\"),\n",
        "    (\"He shaves in the morning\", \"Il se rase le matin\"),\n",
        "    (\"They set the table\", \"Ils mettent la table\"),\n",
        "    (\"The airplane takes off\", \"L'avion décolle\"),\n",
        "    (\"She waters the plants\", \"Elle arrose les plantes\"),\n",
        "    (\"We practice yoga\", \"Nous pratiquons le yoga\"),\n",
        "    (\"He turns off the light\", \"Il éteint la lumière\"),\n",
        "    (\"They play video games\", \"Ils jouent aux jeux vidéo\"),\n",
        "    (\"The soup smells delicious\", \"La soupe sent délicieusement bon\"),\n",
        "    (\"She locks the door\", \"Elle ferme la porte à clé\"),\n",
        "    (\"We enjoy a picnic\", \"Nous profitons d'un pique-nique\"),\n",
        "    (\"He checks his email\", \"Il vérifie ses emails\"),\n",
        "    (\"They go to the gym\", \"Ils vont à la salle de sport\"),\n",
        "    (\"The moon shines brightly\", \"La lune brille intensément\"),\n",
        "    (\"She catches the bus\", \"Elle attrape le bus\"),\n",
        "    (\"We greet our neighbors\", \"Nous saluons nos voisins\"),\n",
        "    (\"He combs his hair\", \"Il se peigne les cheveux\"),\n",
        "    (\"They wave goodbye\", \"Ils font un signe d'adieu\")\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "YcBQ5RORrwc4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3gv2nDvWrefg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import re\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import AdditiveAttention\n",
        "\n",
        "\n",
        "# Plot Attention function (used during evaluation)\n",
        "def plot_attention(input_seq, attention_weights):\n",
        "    attention_weights = attention_weights.squeeze()\n",
        "    plt.matshow(attention_weights, cmap='viridis')\n",
        "    plt.title(f\"Attention Heatmap for: {input_seq}\")\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Load data\n",
        "english_sentences = [pair[0] for pair in english_to_french]\n",
        "french_sentences = [pair[1] for pair in english_to_french]\n",
        "\n",
        "# Tokenizing the text\n",
        "eng_tokenizer = Tokenizer()\n",
        "fr_tokenizer = Tokenizer()\n",
        "\n",
        "eng_tokenizer.fit_on_texts(english_sentences)\n",
        "fr_tokenizer.fit_on_texts(french_sentences)\n",
        "fr_tokenizer.word_index['<start>'] = len(fr_tokenizer.word_index) + 1\n",
        "fr_tokenizer.word_index['<end>'] = len(fr_tokenizer.word_index) + 2\n",
        "\n",
        "# Create input sequences and output sequences\n",
        "encoder_input_sequences = eng_tokenizer.texts_to_sequences(english_sentences)\n",
        "decoder_input_sequences = fr_tokenizer.texts_to_sequences(french_sentences)\n",
        "\n",
        "# Pad sequences to ensure equal length\n",
        "encoder_input_sequences = pad_sequences(encoder_input_sequences, padding='post')\n",
        "decoder_input_sequences = pad_sequences(decoder_input_sequences, padding='post')\n",
        "\n",
        "# Get the maximum lengths and vocabulary sizes\n",
        "max_encoder_seq_length = max([len(seq) for seq in encoder_input_sequences])\n",
        "max_decoder_seq_length = max([len(seq) for seq in decoder_input_sequences])\n",
        "\n",
        "num_encoder_tokens = len(eng_tokenizer.word_index) + 1\n",
        "num_decoder_tokens = len(fr_tokenizer.word_index) + 1\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "latent_dim = 256  # GRU state size\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = layers.Input(shape=(None,))\n",
        "encoder_embedding = layers.Embedding(input_dim=num_encoder_tokens, output_dim=latent_dim)(encoder_inputs)\n",
        "encoder_gru = layers.GRU(latent_dim, return_state=True, return_sequences=True)  # We use return_sequences=True for Attention\n",
        "encoder_outputs, state_h = encoder_gru(encoder_embedding)\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = layers.Input(shape=(None,))\n",
        "decoder_embedding = layers.Embedding(input_dim=num_decoder_tokens, output_dim=latent_dim)(decoder_inputs)\n",
        "\n",
        "# GRU Decoder (we pass initial state from encoder)\n",
        "decoder_gru = layers.GRU(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _ = decoder_gru(decoder_embedding, initial_state=state_h)\n",
        "\n",
        "# Attention Layer\n",
        "attention_layer = layers.AdditiveAttention(use_scale=True)\n",
        "attention_output = attention_layer([decoder_outputs, encoder_outputs])\n",
        "\n",
        "# Concatenate attention output and decoder output\n",
        "context_vector_and_decoder_output = layers.Concatenate(axis=-1)([attention_output, decoder_outputs])\n",
        "\n",
        "# Output layer\n",
        "output = layers.Dense(num_decoder_tokens, activation='softmax')(context_vector_and_decoder_output)\n",
        "\n",
        "# Final Model\n",
        "model = models.Model([encoder_inputs, decoder_inputs], output)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and validation sets\n",
        "X_train=encoder_input_sequences\n",
        "y_train=decoder_input_sequences\n",
        "X_val=encoder_input_sequences\n",
        "y_val=decoder_input_sequences\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    [X_train, y_train], y_train,\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    validation_data=([X_val, y_val], y_val)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEuICaapsmHj",
        "outputId": "511a8b01-573d-4678-e50d-5b8eeb0b4972"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 349ms/step - accuracy: 0.5016 - loss: 2.5634 - val_accuracy: 0.5172 - val_loss: 2.5228\n",
            "Epoch 2/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.5297 - loss: 2.5207 - val_accuracy: 0.5703 - val_loss: 2.4993\n",
            "Epoch 3/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300ms/step - accuracy: 0.5740 - loss: 2.5047 - val_accuracy: 0.5959 - val_loss: 2.4834\n",
            "Epoch 4/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.5982 - loss: 2.4723 - val_accuracy: 0.6067 - val_loss: 2.4450\n",
            "Epoch 5/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 297ms/step - accuracy: 0.6006 - loss: 2.4728 - val_accuracy: 0.6067 - val_loss: 2.4010\n",
            "Epoch 6/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 303ms/step - accuracy: 0.6041 - loss: 2.4062 - val_accuracy: 0.6067 - val_loss: 2.3675\n",
            "Epoch 7/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.5995 - loss: 2.3995 - val_accuracy: 0.6067 - val_loss: 2.3382\n",
            "Epoch 8/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.6070 - loss: 2.3367 - val_accuracy: 0.6067 - val_loss: 2.3033\n",
            "Epoch 9/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.6105 - loss: 2.2739 - val_accuracy: 0.6067 - val_loss: 2.2601\n",
            "Epoch 10/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 276ms/step - accuracy: 0.6041 - loss: 2.2639 - val_accuracy: 0.6077 - val_loss: 2.2132\n",
            "Epoch 11/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564ms/step - accuracy: 0.6053 - loss: 2.2199 - val_accuracy: 0.6087 - val_loss: 2.1683\n",
            "Epoch 12/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 427ms/step - accuracy: 0.6043 - loss: 2.1936 - val_accuracy: 0.6096 - val_loss: 2.1243\n",
            "Epoch 13/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259ms/step - accuracy: 0.6102 - loss: 2.1144 - val_accuracy: 0.6116 - val_loss: 2.0767\n",
            "Epoch 14/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.6157 - loss: 2.0607 - val_accuracy: 0.6195 - val_loss: 2.0254\n",
            "Epoch 15/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - accuracy: 0.6197 - loss: 2.0238 - val_accuracy: 0.6293 - val_loss: 1.9740\n",
            "Epoch 16/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.6285 - loss: 1.9699 - val_accuracy: 0.6421 - val_loss: 1.9229\n",
            "Epoch 17/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 253ms/step - accuracy: 0.6434 - loss: 1.9109 - val_accuracy: 0.6529 - val_loss: 1.8711\n",
            "Epoch 18/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 299ms/step - accuracy: 0.6524 - loss: 1.8773 - val_accuracy: 0.6647 - val_loss: 1.8197\n",
            "Epoch 19/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - accuracy: 0.6643 - loss: 1.8244 - val_accuracy: 0.6696 - val_loss: 1.7700\n",
            "Epoch 20/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 250ms/step - accuracy: 0.6681 - loss: 1.7705 - val_accuracy: 0.6794 - val_loss: 1.7214\n",
            "Epoch 21/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.6775 - loss: 1.7316 - val_accuracy: 0.6824 - val_loss: 1.6736\n",
            "Epoch 22/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 295ms/step - accuracy: 0.6847 - loss: 1.6467 - val_accuracy: 0.6844 - val_loss: 1.6268\n",
            "Epoch 23/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 249ms/step - accuracy: 0.6826 - loss: 1.6331 - val_accuracy: 0.6863 - val_loss: 1.5805\n",
            "Epoch 24/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - accuracy: 0.6909 - loss: 1.5570 - val_accuracy: 0.6971 - val_loss: 1.5347\n",
            "Epoch 25/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255ms/step - accuracy: 0.6986 - loss: 1.5139 - val_accuracy: 0.7011 - val_loss: 1.4885\n",
            "Epoch 26/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.7012 - loss: 1.4808 - val_accuracy: 0.7070 - val_loss: 1.4421\n",
            "Epoch 27/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300ms/step - accuracy: 0.7087 - loss: 1.4310 - val_accuracy: 0.7168 - val_loss: 1.3955\n",
            "Epoch 28/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.7168 - loss: 1.3752 - val_accuracy: 0.7257 - val_loss: 1.3485\n",
            "Epoch 29/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 298ms/step - accuracy: 0.7241 - loss: 1.3561 - val_accuracy: 0.7296 - val_loss: 1.3012\n",
            "Epoch 30/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 311ms/step - accuracy: 0.7279 - loss: 1.3018 - val_accuracy: 0.7355 - val_loss: 1.2539\n",
            "Epoch 31/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 419ms/step - accuracy: 0.7364 - loss: 1.2454 - val_accuracy: 0.7434 - val_loss: 1.2066\n",
            "Epoch 32/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571ms/step - accuracy: 0.7470 - loss: 1.1868 - val_accuracy: 0.7522 - val_loss: 1.1597\n",
            "Epoch 33/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296ms/step - accuracy: 0.7515 - loss: 1.1530 - val_accuracy: 0.7611 - val_loss: 1.1129\n",
            "Epoch 34/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 312ms/step - accuracy: 0.7676 - loss: 1.1003 - val_accuracy: 0.7768 - val_loss: 1.0664\n",
            "Epoch 35/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.7737 - loss: 1.0810 - val_accuracy: 0.7896 - val_loss: 1.0200\n",
            "Epoch 36/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.7962 - loss: 0.9972 - val_accuracy: 0.8014 - val_loss: 0.9744\n",
            "Epoch 37/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.8000 - loss: 0.9803 - val_accuracy: 0.8181 - val_loss: 0.9290\n",
            "Epoch 38/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 319ms/step - accuracy: 0.8175 - loss: 0.9274 - val_accuracy: 0.8299 - val_loss: 0.8840\n",
            "Epoch 39/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255ms/step - accuracy: 0.8317 - loss: 0.8792 - val_accuracy: 0.8486 - val_loss: 0.8395\n",
            "Epoch 40/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.8475 - loss: 0.8362 - val_accuracy: 0.8673 - val_loss: 0.7956\n",
            "Epoch 41/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - accuracy: 0.8664 - loss: 0.7983 - val_accuracy: 0.8840 - val_loss: 0.7524\n",
            "Epoch 42/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.8850 - loss: 0.7459 - val_accuracy: 0.8958 - val_loss: 0.7100\n",
            "Epoch 43/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.8959 - loss: 0.6980 - val_accuracy: 0.9125 - val_loss: 0.6683\n",
            "Epoch 44/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.9148 - loss: 0.6653 - val_accuracy: 0.9312 - val_loss: 0.6276\n",
            "Epoch 45/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 297ms/step - accuracy: 0.9293 - loss: 0.6242 - val_accuracy: 0.9449 - val_loss: 0.5880\n",
            "Epoch 46/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.9448 - loss: 0.5870 - val_accuracy: 0.9518 - val_loss: 0.5496\n",
            "Epoch 47/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 251ms/step - accuracy: 0.9554 - loss: 0.5392 - val_accuracy: 0.9617 - val_loss: 0.5127\n",
            "Epoch 48/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 295ms/step - accuracy: 0.9617 - loss: 0.5049 - val_accuracy: 0.9705 - val_loss: 0.4773\n",
            "Epoch 49/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 301ms/step - accuracy: 0.9699 - loss: 0.4738 - val_accuracy: 0.9774 - val_loss: 0.4435\n",
            "Epoch 50/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.9750 - loss: 0.4445 - val_accuracy: 0.9833 - val_loss: 0.4114\n",
            "Epoch 51/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9836 - loss: 0.4122 - val_accuracy: 0.9882 - val_loss: 0.3813\n",
            "Epoch 52/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 400ms/step - accuracy: 0.9881 - loss: 0.3800 - val_accuracy: 0.9921 - val_loss: 0.3531\n",
            "Epoch 53/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step - accuracy: 0.9948 - loss: 0.3477 - val_accuracy: 0.9931 - val_loss: 0.3267\n",
            "Epoch 54/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300ms/step - accuracy: 0.9938 - loss: 0.3266 - val_accuracy: 0.9980 - val_loss: 0.3019\n",
            "Epoch 55/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.9981 - loss: 0.2994 - val_accuracy: 0.9980 - val_loss: 0.2791\n",
            "Epoch 56/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 307ms/step - accuracy: 0.9975 - loss: 0.2722 - val_accuracy: 0.9980 - val_loss: 0.2580\n",
            "Epoch 57/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 313ms/step - accuracy: 0.9981 - loss: 0.2533 - val_accuracy: 0.9990 - val_loss: 0.2382\n",
            "Epoch 58/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 302ms/step - accuracy: 0.9993 - loss: 0.2372 - val_accuracy: 0.9990 - val_loss: 0.2199\n",
            "Epoch 59/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259ms/step - accuracy: 0.9988 - loss: 0.2192 - val_accuracy: 1.0000 - val_loss: 0.2030\n",
            "Epoch 60/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 1.0000 - loss: 0.1987 - val_accuracy: 1.0000 - val_loss: 0.1875\n",
            "Epoch 61/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 1.0000 - loss: 0.1874 - val_accuracy: 1.0000 - val_loss: 0.1731\n",
            "Epoch 62/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 1.0000 - loss: 0.1725 - val_accuracy: 1.0000 - val_loss: 0.1599\n",
            "Epoch 63/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 1.0000 - loss: 0.1567 - val_accuracy: 1.0000 - val_loss: 0.1478\n",
            "Epoch 64/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300ms/step - accuracy: 1.0000 - loss: 0.1458 - val_accuracy: 1.0000 - val_loss: 0.1366\n",
            "Epoch 65/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 253ms/step - accuracy: 1.0000 - loss: 0.1349 - val_accuracy: 1.0000 - val_loss: 0.1264\n",
            "Epoch 66/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300ms/step - accuracy: 1.0000 - loss: 0.1267 - val_accuracy: 1.0000 - val_loss: 0.1170\n",
            "Epoch 67/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 0.1155 - val_accuracy: 1.0000 - val_loss: 0.1084\n",
            "Epoch 68/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 1.0000 - loss: 0.1079 - val_accuracy: 1.0000 - val_loss: 0.1004\n",
            "Epoch 69/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 0.1004 - val_accuracy: 1.0000 - val_loss: 0.0931\n",
            "Epoch 70/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 1.0000 - loss: 0.0899 - val_accuracy: 1.0000 - val_loss: 0.0864\n",
            "Epoch 71/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 1.0000 - loss: 0.0843 - val_accuracy: 1.0000 - val_loss: 0.0804\n",
            "Epoch 72/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 1.0000 - loss: 0.0774 - val_accuracy: 1.0000 - val_loss: 0.0748\n",
            "Epoch 73/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 352ms/step - accuracy: 1.0000 - loss: 0.0745 - val_accuracy: 1.0000 - val_loss: 0.0697\n",
            "Epoch 74/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 400ms/step - accuracy: 1.0000 - loss: 0.0698 - val_accuracy: 1.0000 - val_loss: 0.0650\n",
            "Epoch 75/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 422ms/step - accuracy: 1.0000 - loss: 0.0643 - val_accuracy: 1.0000 - val_loss: 0.0607\n",
            "Epoch 76/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 0.0610 - val_accuracy: 1.0000 - val_loss: 0.0568\n",
            "Epoch 77/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 1.0000 - loss: 0.0556 - val_accuracy: 1.0000 - val_loss: 0.0532\n",
            "Epoch 78/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 1.0000 - loss: 0.0539 - val_accuracy: 1.0000 - val_loss: 0.0500\n",
            "Epoch 79/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 1.0000 - loss: 0.0487 - val_accuracy: 1.0000 - val_loss: 0.0470\n",
            "Epoch 80/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 1.0000 - loss: 0.0477 - val_accuracy: 1.0000 - val_loss: 0.0443\n",
            "Epoch 81/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 302ms/step - accuracy: 1.0000 - loss: 0.0426 - val_accuracy: 1.0000 - val_loss: 0.0418\n",
            "Epoch 82/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 1.0000 - loss: 0.0412 - val_accuracy: 1.0000 - val_loss: 0.0395\n",
            "Epoch 83/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 1.0000 - loss: 0.0401 - val_accuracy: 1.0000 - val_loss: 0.0373\n",
            "Epoch 84/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 248ms/step - accuracy: 1.0000 - loss: 0.0370 - val_accuracy: 1.0000 - val_loss: 0.0354\n",
            "Epoch 85/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 1.0000 - loss: 0.0350 - val_accuracy: 1.0000 - val_loss: 0.0336\n",
            "Epoch 86/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 0.0329 - val_accuracy: 1.0000 - val_loss: 0.0320\n",
            "Epoch 87/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 0.0316 - val_accuracy: 1.0000 - val_loss: 0.0305\n",
            "Epoch 88/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 1.0000 - loss: 0.0301 - val_accuracy: 1.0000 - val_loss: 0.0290\n",
            "Epoch 89/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 1.0000 - loss: 0.0289 - val_accuracy: 1.0000 - val_loss: 0.0277\n",
            "Epoch 90/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 1.0000 - loss: 0.0276 - val_accuracy: 1.0000 - val_loss: 0.0265\n",
            "Epoch 91/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 252ms/step - accuracy: 1.0000 - loss: 0.0255 - val_accuracy: 1.0000 - val_loss: 0.0254\n",
            "Epoch 92/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 299ms/step - accuracy: 1.0000 - loss: 0.0260 - val_accuracy: 1.0000 - val_loss: 0.0243\n",
            "Epoch 93/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 1.0000 - loss: 0.0243 - val_accuracy: 1.0000 - val_loss: 0.0234\n",
            "Epoch 94/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300ms/step - accuracy: 1.0000 - loss: 0.0230 - val_accuracy: 1.0000 - val_loss: 0.0224\n",
            "Epoch 95/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522ms/step - accuracy: 1.0000 - loss: 0.0217 - val_accuracy: 1.0000 - val_loss: 0.0216\n",
            "Epoch 96/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 410ms/step - accuracy: 1.0000 - loss: 0.0211 - val_accuracy: 1.0000 - val_loss: 0.0208\n",
            "Epoch 97/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 0.0205 - val_accuracy: 1.0000 - val_loss: 0.0200\n",
            "Epoch 98/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300ms/step - accuracy: 1.0000 - loss: 0.0200 - val_accuracy: 1.0000 - val_loss: 0.0193\n",
            "Epoch 99/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 294ms/step - accuracy: 1.0000 - loss: 0.0194 - val_accuracy: 1.0000 - val_loss: 0.0186\n",
            "Epoch 100/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 1.0000 - loss: 0.0192 - val_accuracy: 1.0000 - val_loss: 0.0180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference Encoder Model\n",
        "# Example for the encoder model\n",
        "encoder_inputs_inf = layers.Input(shape=(None,))  # Shape (None, ?) for input sequence\n",
        "print(\"Encoder Input Shape: \", encoder_inputs_inf.shape)\n",
        "\n",
        "encoder_embedding_inf = layers.Embedding(input_dim=num_encoder_tokens, output_dim=latent_dim)(encoder_inputs_inf)\n",
        "print(\"Encoder Embedding Shape: \", encoder_embedding_inf.shape)\n",
        "\n",
        "encoder_gru_inf = layers.GRU(latent_dim, return_state=True, return_sequences=True)\n",
        "encoder_outputs_inf, state_h_inf = encoder_gru_inf(encoder_embedding_inf)\n",
        "print(\"Encoder GRU Output Shape: \", encoder_outputs_inf.shape)\n",
        "print(\"Encoder Hidden State Shape: \", state_h_inf.shape)\n",
        "\n",
        "# Create the inference encoder model\n",
        "encoder_model = models.Model(encoder_inputs_inf, [encoder_outputs_inf, state_h_inf])\n",
        "def attention_layer(inputs):\n",
        "    decoder_outputs, encoder_outputs = inputs\n",
        "    attention_scores = layers.Attention()([decoder_outputs, encoder_outputs])  # Attention mechanism\n",
        "    return attention_scores\n",
        "\n",
        "\n",
        "# Inference Decoder Model (after training)\n",
        "# Inference Decoder Model (after training)\n",
        "decoder_state_input_h = layers.Input(shape=(latent_dim,), name='decoder_state_input_h')  # Hidden state from encoder\n",
        "decoder_inputs_inf = layers.Input(shape=(1,), name='decoder_inputs_inf')  # Input token at each timestep\n",
        "# Pass encoder outputs as an input for attention:\n",
        "encoder_outputs_inf_dec = layers.Input(shape=(max_encoder_seq_length, latent_dim), name='encoder_outputs_inf_dec')\n",
        "\n",
        "decoder_embedding_inf = layers.Embedding(input_dim=num_decoder_tokens, output_dim=latent_dim)(decoder_inputs_inf)\n",
        "decoder_gru_inf = layers.GRU(latent_dim, return_sequences=True, return_state=True)\n",
        "\n",
        "# Pass the decoder embedding through the GRU with initial state from encoder\n",
        "decoder_outputs_inf, state_h_inf = decoder_gru_inf(decoder_embedding_inf, initial_state=decoder_state_input_h)\n",
        "\n",
        "# Apply attention mechanism\n",
        "attention_output_inf = attention_layer([decoder_outputs_inf, encoder_outputs_inf_dec]) # Use passed encoder outputs\n",
        "\n",
        "# Concatenate attention output with decoder output\n",
        "context_vector_and_decoder_output_inf = layers.Concatenate(axis=-1)([attention_output_inf, decoder_outputs_inf])\n",
        "\n",
        "# Output layer: Predict next token using softmax activation\n",
        "output_inf = layers.Dense(num_decoder_tokens, activation='softmax')(context_vector_and_decoder_output_inf)\n",
        "\n",
        "# Final Decoder Model: Takes both decoder inputs, decoder state inputs, and encoder outputs for attention\n",
        "decoder_model = models.Model([decoder_inputs_inf, decoder_state_input_h, encoder_outputs_inf_dec], [output_inf, state_h_inf])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OEzKzUms0jR",
        "outputId": "3906b312-c34a-42b9-a7f4-d40d8f913da2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder Input Shape:  (None, None)\n",
            "Encoder Embedding Shape:  (None, None, 256)\n",
            "Encoder GRU Output Shape:  (None, None, 256)\n",
            "Encoder Hidden State Shape:  (None, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_translation(input_seq):\n",
        "    # Step 1: Encode the input sequence using the encoder model\n",
        "    encoder_outputs_val, state_h_val = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Step 2: Initialize the target sequence with the <start> token\n",
        "    target_seq = np.array([[fr_tokenizer.word_index['<start>']]])\n",
        "\n",
        "    # Step 3: Initialize an empty string to store the translated sentence\n",
        "    translated_sentence = ''\n",
        "\n",
        "    # Step 4: Generate the output sequence token by token\n",
        "    for _ in range(max_decoder_seq_length):\n",
        "        print(f\"target_seq shape: {target_seq.shape}\")  # Should be (1, 1)\n",
        "        print(f\"state_h_val shape: {state_h_val.shape}\")  # Should be (1, 256)\n",
        "\n",
        "        # Predict the next token (French word) from the decoder model\n",
        "        output_tokens, state_h_val = decoder_model.predict(\n",
        "            [target_seq, state_h_val, encoder_outputs_val]\n",
        "        )\n",
        "\n",
        "        # Get the most probable next token\n",
        "        predicted_token = np.argmax(output_tokens[0, -1, :])\n",
        "\n",
        "        # Check if the predicted token is in the index_word dictionary\n",
        "        if predicted_token in fr_tokenizer.index_word:\n",
        "            predicted_word = fr_tokenizer.index_word[predicted_token]\n",
        "        else:\n",
        "            print(f\"Predicted token {predicted_token} is not in index_word dictionary\")\n",
        "            predicted_word = \"<unknown>\"\n",
        "\n",
        "        translated_sentence += ' ' + predicted_word\n",
        "\n",
        "        # Stop if the <end> token is predicted\n",
        "        if predicted_word == '<end>':\n",
        "            break\n",
        "\n",
        "        # Update the target sequence for the next step\n",
        "        target_seq = np.array([[predicted_token]])\n",
        "\n",
        "    return translated_sentence.strip()\n",
        "\n",
        "\n",
        "\n",
        "# Example usage (Translate some English sentences)\n",
        "english_example = \"I am cold\"\n",
        "input_seq = eng_tokenizer.texts_to_sequences([english_example])\n",
        "input_seq = pad_sequences(input_seq, maxlen=max_encoder_seq_length, padding='post')\n",
        "\n",
        "print(f\"English: {english_example}\")\n",
        "print(f\"French: {generate_translation(input_seq)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IvRz-D9tCsy",
        "outputId": "b84fb23d-029e-4a92-e846-4262d417f7e8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English: I am cold\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "target_seq shape: (1, 1)\n",
            "state_h_val shape: (1, 256)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "target_seq shape: (1, 1)\n",
            "state_h_val shape: (1, 256)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "target_seq shape: (1, 1)\n",
            "state_h_val shape: (1, 256)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "target_seq shape: (1, 1)\n",
            "state_h_val shape: (1, 256)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "target_seq shape: (1, 1)\n",
            "state_h_val shape: (1, 256)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "target_seq shape: (1, 1)\n",
            "state_h_val shape: (1, 256)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "target_seq shape: (1, 1)\n",
            "state_h_val shape: (1, 256)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "target_seq shape: (1, 1)\n",
            "state_h_val shape: (1, 256)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "target_seq shape: (1, 1)\n",
            "state_h_val shape: (1, 256)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "French: bon enfants enfants enfants chat chat arrose enfants chat\n"
          ]
        }
      ]
    }
  ]
}
