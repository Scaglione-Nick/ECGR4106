{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEmxYGTH9AyIKSmWebAlfk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Scaglione-Nick/ECGR4106/blob/main/pt3_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_to_french = [\n",
        "\n",
        "    (\"I am cold\", \"J'ai froid\"),\n",
        "    (\"You are tired\", \"Tu es fatigué\"),\n",
        "    (\"He is hungry\", \"Il a faim\"),\n",
        "    (\"She is happy\", \"Elle est heureuse\"),\n",
        "    (\"We are friends\", \"Nous sommes amis\"),\n",
        "    (\"They are students\", \"Ils sont étudiants\"),\n",
        "    (\"The cat is sleeping\", \"Le chat dort\"),\n",
        "    (\"The sun is shining\", \"Le soleil brille\"),\n",
        "    (\"We love music\", \"Nous aimons la musique\"),\n",
        "    (\"She speaks French fluently\", \"Elle parle français couramment\"),\n",
        "    (\"He enjoys reading books\", \"Il aime lire des livres\"),\n",
        "    (\"They play soccer every weekend\", \"Ils jouent au football chaque week-end\"),\n",
        "    (\"The movie starts at 7 PM\", \"Le film commence à 19 heures\"),\n",
        "    (\"She wears a red dress\", \"Elle porte une robe rouge\"),\n",
        "    (\"We cook dinner together\", \"Nous cuisinons le dîner ensemble\"),\n",
        "    (\"He drives a blue car\", \"Il conduit une voiture bleue\"),\n",
        "    (\"They visit museums often\", \"Ils visitent souvent des musées\"),\n",
        "    (\"The restaurant serves delicious food\", \"Le restaurant sert une délicieuse cuisine\"),\n",
        "    (\"She studies mathematics at university\", \"Elle étudie les mathématiques à l'université\"),\n",
        "    (\"We watch movies on Fridays\", \"Nous regardons des films le vendredi\"),\n",
        "    (\"He listens to music while jogging\", \"Il écoute de la musique en faisant du jogging\"),\n",
        "    (\"They travel around the world\", \"Ils voyagent autour du monde\"),\n",
        "    (\"The book is on the table\", \"Le livre est sur la table\"),\n",
        "    (\"She dances gracefully\", \"Elle danse avec grâce\"),\n",
        "    (\"We celebrate birthdays with cake\", \"Nous célébrons les anniversaires avec un gâteau\"),\n",
        "    (\"He works hard every day\", \"Il travaille dur tous les jours\"),\n",
        "    (\"They speak different languages\", \"Ils parlent différentes langues\"),\n",
        "    (\"The flowers bloom in spring\", \"Les fleurs fleurissent au printemps\"),\n",
        "    (\"She writes poetry in her free time\", \"Elle écrit de la poésie pendant son temps libre\"),\n",
        "    (\"We learn something new every day\", \"Nous apprenons quelque chose de nouveau chaque jour\"),\n",
        "    (\"The dog barks loudly\", \"Le chien aboie bruyamment\"),\n",
        "    (\"He sings beautifully\", \"Il chante magnifiquement\"),\n",
        "    (\"They swim in the pool\", \"Ils nagent dans la piscine\"),\n",
        "    (\"The birds chirp in the morning\", \"Les oiseaux gazouillent le matin\"),\n",
        "    (\"She teaches English at school\", \"Elle enseigne l'anglais à l'école\"),\n",
        "    (\"We eat breakfast together\", \"Nous prenons le petit déjeuner ensemble\"),\n",
        "    (\"He paints landscapes\", \"Il peint des paysages\"),\n",
        "    (\"They laugh at the joke\", \"Ils rient de la blague\"),\n",
        "    (\"The clock ticks loudly\", \"L'horloge tic-tac bruyamment\"),\n",
        "    (\"She runs in the park\", \"Elle court dans le parc\"),\n",
        "    (\"We travel by train\", \"Nous voyageons en train\"),\n",
        "    (\"He writes a letter\", \"Il écrit une lettre\"),\n",
        "    (\"They read books at the library\", \"Ils lisent des livres à la bibliothèque\"),\n",
        "    (\"The baby cries\", \"Le bébé pleure\"),\n",
        "    (\"She studies hard for exams\", \"Elle étudie dur pour les examens\"),\n",
        "    (\"We plant flowers in the garden\", \"Nous plantons des fleurs dans le jardin\"),\n",
        "    (\"He fixes the car\", \"Il répare la voiture\"),\n",
        "    (\"They drink coffee in the morning\", \"Ils boivent du café le matin\"),\n",
        "    (\"The sun sets in the evening\", \"Le soleil se couche le soir\"),\n",
        "    (\"She dances at the party\", \"Elle danse à la fête\"),\n",
        "    (\"We play music at the concert\", \"Nous jouons de la musique au concert\"),\n",
        "    (\"He cooks dinner for his family\", \"Il cuisine le dîner pour sa famille\"),\n",
        "    (\"They study French grammar\", \"Ils étudient la grammaire française\"),\n",
        "    (\"The rain falls gently\", \"La pluie tombe doucement\"),\n",
        "    (\"She sings a song\", \"Elle chante une chanson\"),\n",
        "    (\"We watch a movie together\", \"Nous regardons un film ensemble\"),\n",
        "    (\"He sleeps deeply\", \"Il dort profondément\"),\n",
        "    (\"They travel to Paris\", \"Ils voyagent à Paris\"),\n",
        "    (\"The children play in the park\", \"Les enfants jouent dans le parc\"),\n",
        "    (\"She walks along the beach\", \"Elle se promène le long de la plage\"),\n",
        "    (\"We talk on the phone\", \"Nous parlons au téléphone\"),\n",
        "    (\"He waits for the bus\", \"Il attend le bus\"),\n",
        "    (\"They visit the Eiffel Tower\", \"Ils visitent la tour Eiffel\"),\n",
        "    (\"The stars twinkle at night\", \"Les étoiles scintillent la nuit\"),\n",
        "    (\"She dreams of flying\", \"Elle rêve de voler\"),\n",
        "    (\"We work in the office\", \"Nous travaillons au bureau\"),\n",
        "    (\"He studies history\", \"Il étudie l'histoire\"),\n",
        "    (\"They listen to the radio\", \"Ils écoutent la radio\"),\n",
        "    (\"The wind blows gently\", \"Le vent souffle doucement\"),\n",
        "    (\"She swims in the ocean\", \"Elle nage dans l'océan\"),\n",
        "    (\"We dance at the wedding\", \"Nous dansons au mariage\"),\n",
        "    (\"He climbs the mountain\", \"Il gravit la montagne\"),\n",
        "    (\"They hike in the forest\", \"Ils font de la randonnée dans la forêt\"),\n",
        "    (\"The cat meows loudly\", \"Le chat miaule bruyamment\"),\n",
        "    (\"She paints a picture\", \"Elle peint un tableau\"),\n",
        "    (\"We build a sandcastle\", \"Nous construisons un château de sable\"),\n",
        "    (\"He sings in the choir\", \"Il chante dans le chœur\"),\n",
        "    (\"They ride bicycles\", \"Ils font du vélo\"),\n",
        "    (\"The coffee is hot\", \"Le café est chaud\"),\n",
        "    (\"She wears glasses\", \"Elle porte des lunettes\"),\n",
        "    (\"We visit our grandparents\", \"Nous rendons visite à nos grands-parents\"),\n",
        "    (\"He plays the guitar\", \"Il joue de la guitare\"),\n",
        "    (\"They go shopping\", \"Ils font du shopping\"),\n",
        "    (\"The teacher explains the lesson\", \"Le professeur explique la leçon\"),\n",
        "    (\"She takes the train to work\", \"Elle prend le train pour aller au travail\"),\n",
        "    (\"We bake cookies\", \"Nous faisons des biscuits\"),\n",
        "    (\"He washes his hands\", \"Il se lave les mains\"),\n",
        "    (\"They enjoy the sunset\", \"Ils apprécient le coucher du soleil\"),\n",
        "    (\"The river flows calmly\", \"La rivière coule calmement\"),\n",
        "    (\"She feeds the cat\", \"Elle nourrit le chat\"),\n",
        "    (\"We visit the museum\", \"Nous visitons le musée\"),\n",
        "    (\"He fixes his bicycle\", \"Il répare son vélo\"),\n",
        "    (\"They paint the walls\", \"Ils peignent les murs\"),\n",
        "    (\"The baby sleeps peacefully\", \"Le bébé dort paisiblement\"),\n",
        "    (\"She ties her shoelaces\", \"Elle attache ses lacets\"),\n",
        "    (\"We climb the stairs\", \"Nous montons les escaliers\"),\n",
        "    (\"He shaves in the morning\", \"Il se rase le matin\"),\n",
        "    (\"They set the table\", \"Ils mettent la table\"),\n",
        "    (\"The airplane takes off\", \"L'avion décolle\"),\n",
        "    (\"She waters the plants\", \"Elle arrose les plantes\"),\n",
        "    (\"We practice yoga\", \"Nous pratiquons le yoga\"),\n",
        "    (\"He turns off the light\", \"Il éteint la lumière\"),\n",
        "    (\"They play video games\", \"Ils jouent aux jeux vidéo\"),\n",
        "    (\"The soup smells delicious\", \"La soupe sent délicieusement bon\"),\n",
        "    (\"She locks the door\", \"Elle ferme la porte à clé\"),\n",
        "    (\"We enjoy a picnic\", \"Nous profitons d'un pique-nique\"),\n",
        "    (\"He checks his email\", \"Il vérifie ses emails\"),\n",
        "    (\"They go to the gym\", \"Ils vont à la salle de sport\"),\n",
        "    (\"The moon shines brightly\", \"La lune brille intensément\"),\n",
        "    (\"She catches the bus\", \"Elle attrape le bus\"),\n",
        "    (\"We greet our neighbors\", \"Nous saluons nos voisins\"),\n",
        "    (\"He combs his hair\", \"Il se peigne les cheveux\"),\n",
        "    (\"They wave goodbye\", \"Ils font un signe d'adieu\")\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "YcBQ5RORrwc4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3gv2nDvWrefg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import re\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import AdditiveAttention\n",
        "\n",
        "\n",
        "# Plot Attention function (used during evaluation)\n",
        "def plot_attention(input_seq, attention_weights):\n",
        "    attention_weights = attention_weights.squeeze()\n",
        "    plt.matshow(attention_weights, cmap='viridis')\n",
        "    plt.title(f\"Attention Heatmap for: {input_seq}\")\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Load data\n",
        "english_sentences = [pair[1] for pair in english_to_french]\n",
        "french_sentences = [pair[0] for pair in english_to_french]\n",
        "\n",
        "# Tokenizing the text\n",
        "eng_tokenizer = Tokenizer()\n",
        "fr_tokenizer = Tokenizer()\n",
        "\n",
        "eng_tokenizer.fit_on_texts(english_sentences)\n",
        "fr_tokenizer.fit_on_texts(french_sentences)\n",
        "fr_tokenizer.word_index['<start>'] = len(fr_tokenizer.word_index) + 1\n",
        "fr_tokenizer.word_index['<end>'] = len(fr_tokenizer.word_index) + 2\n",
        "\n",
        "# Create input sequences and output sequences\n",
        "encoder_input_sequences = eng_tokenizer.texts_to_sequences(english_sentences)\n",
        "decoder_input_sequences = fr_tokenizer.texts_to_sequences(french_sentences)\n",
        "\n",
        "# Pad sequences to ensure equal length\n",
        "encoder_input_sequences = pad_sequences(encoder_input_sequences, padding='post')\n",
        "decoder_input_sequences = pad_sequences(decoder_input_sequences, padding='post')\n",
        "\n",
        "# Get the maximum lengths and vocabulary sizes\n",
        "max_encoder_seq_length = max([len(seq) for seq in encoder_input_sequences])\n",
        "max_decoder_seq_length = max([len(seq) for seq in decoder_input_sequences])\n",
        "\n",
        "num_encoder_tokens = len(eng_tokenizer.word_index) + 1\n",
        "num_decoder_tokens = len(fr_tokenizer.word_index) + 1\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "latent_dim = 256  # GRU state size\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = layers.Input(shape=(None,))\n",
        "encoder_embedding = layers.Embedding(input_dim=num_encoder_tokens, output_dim=latent_dim)(encoder_inputs)\n",
        "encoder_gru = layers.GRU(latent_dim, return_state=True, return_sequences=True)  # We use return_sequences=True for Attention\n",
        "encoder_outputs, state_h = encoder_gru(encoder_embedding)\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = layers.Input(shape=(None,))\n",
        "decoder_embedding = layers.Embedding(input_dim=num_decoder_tokens, output_dim=latent_dim)(decoder_inputs)\n",
        "\n",
        "# GRU Decoder (we pass initial state from encoder)\n",
        "decoder_gru = layers.GRU(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _ = decoder_gru(decoder_embedding, initial_state=state_h)\n",
        "\n",
        "# Attention Layer\n",
        "attention_layer = layers.AdditiveAttention(use_scale=True)\n",
        "attention_output = attention_layer([decoder_outputs, encoder_outputs])\n",
        "\n",
        "# Concatenate attention output and decoder output\n",
        "context_vector_and_decoder_output = layers.Concatenate(axis=-1)([attention_output, decoder_outputs])\n",
        "\n",
        "# Output layer\n",
        "output = layers.Dense(num_decoder_tokens, activation='softmax')(context_vector_and_decoder_output)\n",
        "\n",
        "# Final Model\n",
        "model = models.Model([encoder_inputs, decoder_inputs], output)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and validation sets\n",
        "X_train=encoder_input_sequences\n",
        "y_train=decoder_input_sequences\n",
        "X_val=encoder_input_sequences\n",
        "y_val=decoder_input_sequences\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    [X_train, y_train], y_train,\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    validation_data=([X_val, y_val], y_val)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEuICaapsmHj",
        "outputId": "7749df5f-3c2c-4cd3-e7af-ec52392db5ad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.1062 - loss: 5.4972 - val_accuracy: 0.3755 - val_loss: 5.3206\n",
            "Epoch 2/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.3761 - loss: 5.2813 - val_accuracy: 0.3755 - val_loss: 5.0006\n",
            "Epoch 3/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 253ms/step - accuracy: 0.3753 - loss: 4.9261 - val_accuracy: 0.3755 - val_loss: 4.3812\n",
            "Epoch 4/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.3805 - loss: 4.2364 - val_accuracy: 0.3755 - val_loss: 3.4710\n",
            "Epoch 5/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - accuracy: 0.3716 - loss: 3.5250 - val_accuracy: 0.3755 - val_loss: 3.5177\n",
            "Epoch 6/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 0.3761 - loss: 3.4388 - val_accuracy: 0.4286 - val_loss: 3.0788\n",
            "Epoch 7/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289ms/step - accuracy: 0.4333 - loss: 3.0545 - val_accuracy: 0.4678 - val_loss: 2.9924\n",
            "Epoch 8/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.4664 - loss: 3.0081 - val_accuracy: 0.4665 - val_loss: 2.9365\n",
            "Epoch 9/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.4626 - loss: 2.9294 - val_accuracy: 0.4564 - val_loss: 2.8587\n",
            "Epoch 10/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 298ms/step - accuracy: 0.4605 - loss: 2.8415 - val_accuracy: 0.4564 - val_loss: 2.8018\n",
            "Epoch 11/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 235ms/step - accuracy: 0.4591 - loss: 2.7883 - val_accuracy: 0.4576 - val_loss: 2.7536\n",
            "Epoch 12/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.4676 - loss: 2.7454 - val_accuracy: 0.5651 - val_loss: 2.6923\n",
            "Epoch 13/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 232ms/step - accuracy: 0.5665 - loss: 2.6821 - val_accuracy: 0.5651 - val_loss: 2.6336\n",
            "Epoch 14/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.5628 - loss: 2.6374 - val_accuracy: 0.5664 - val_loss: 2.5798\n",
            "Epoch 15/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.5636 - loss: 2.5878 - val_accuracy: 0.5664 - val_loss: 2.5235\n",
            "Epoch 16/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 302ms/step - accuracy: 0.5681 - loss: 2.5109 - val_accuracy: 0.5664 - val_loss: 2.4607\n",
            "Epoch 17/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.5599 - loss: 2.4805 - val_accuracy: 0.5664 - val_loss: 2.3950\n",
            "Epoch 18/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.5666 - loss: 2.3943 - val_accuracy: 0.5664 - val_loss: 2.3316\n",
            "Epoch 19/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 238ms/step - accuracy: 0.5725 - loss: 2.2996 - val_accuracy: 0.5664 - val_loss: 2.2705\n",
            "Epoch 20/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - accuracy: 0.5703 - loss: 2.2450 - val_accuracy: 0.5676 - val_loss: 2.2100\n",
            "Epoch 21/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - accuracy: 0.5644 - loss: 2.2110 - val_accuracy: 0.5765 - val_loss: 2.1509\n",
            "Epoch 22/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 403ms/step - accuracy: 0.5789 - loss: 2.1615 - val_accuracy: 0.5942 - val_loss: 2.0930\n",
            "Epoch 23/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542ms/step - accuracy: 0.5936 - loss: 2.1001 - val_accuracy: 0.6094 - val_loss: 2.0355\n",
            "Epoch 24/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 305ms/step - accuracy: 0.6140 - loss: 2.0193 - val_accuracy: 0.6169 - val_loss: 1.9791\n",
            "Epoch 25/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.6175 - loss: 1.9772 - val_accuracy: 0.6233 - val_loss: 1.9256\n",
            "Epoch 26/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265ms/step - accuracy: 0.6225 - loss: 1.9185 - val_accuracy: 0.6308 - val_loss: 1.8746\n",
            "Epoch 27/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.6363 - loss: 1.8495 - val_accuracy: 0.6359 - val_loss: 1.8247\n",
            "Epoch 28/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.6369 - loss: 1.8314 - val_accuracy: 0.6435 - val_loss: 1.7756\n",
            "Epoch 29/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 233ms/step - accuracy: 0.6425 - loss: 1.7773 - val_accuracy: 0.6536 - val_loss: 1.7276\n",
            "Epoch 30/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.6560 - loss: 1.7182 - val_accuracy: 0.6612 - val_loss: 1.6796\n",
            "Epoch 31/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.6612 - loss: 1.6815 - val_accuracy: 0.6688 - val_loss: 1.6309\n",
            "Epoch 32/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.6667 - loss: 1.6298 - val_accuracy: 0.6738 - val_loss: 1.5820\n",
            "Epoch 33/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - accuracy: 0.6776 - loss: 1.5712 - val_accuracy: 0.6789 - val_loss: 1.5331\n",
            "Epoch 34/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 295ms/step - accuracy: 0.6720 - loss: 1.5357 - val_accuracy: 0.6839 - val_loss: 1.4840\n",
            "Epoch 35/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - accuracy: 0.6815 - loss: 1.4948 - val_accuracy: 0.6941 - val_loss: 1.4349\n",
            "Epoch 36/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 235ms/step - accuracy: 0.6919 - loss: 1.4515 - val_accuracy: 0.7042 - val_loss: 1.3861\n",
            "Epoch 37/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.7047 - loss: 1.3824 - val_accuracy: 0.7155 - val_loss: 1.3376\n",
            "Epoch 38/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.7152 - loss: 1.3366 - val_accuracy: 0.7257 - val_loss: 1.2892\n",
            "Epoch 39/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.7248 - loss: 1.2905 - val_accuracy: 0.7295 - val_loss: 1.2411\n",
            "Epoch 40/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 293ms/step - accuracy: 0.7345 - loss: 1.2360 - val_accuracy: 0.7509 - val_loss: 1.1933\n",
            "Epoch 41/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.7528 - loss: 1.1747 - val_accuracy: 0.7611 - val_loss: 1.1460\n",
            "Epoch 42/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.7644 - loss: 1.1393 - val_accuracy: 0.7788 - val_loss: 1.0991\n",
            "Epoch 43/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.7804 - loss: 1.0894 - val_accuracy: 0.7927 - val_loss: 1.0525\n",
            "Epoch 44/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344ms/step - accuracy: 0.7904 - loss: 1.0483 - val_accuracy: 0.8205 - val_loss: 1.0065\n",
            "Epoch 45/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 396ms/step - accuracy: 0.8178 - loss: 1.0095 - val_accuracy: 0.8369 - val_loss: 0.9612\n",
            "Epoch 46/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 416ms/step - accuracy: 0.8425 - loss: 0.9696 - val_accuracy: 0.8609 - val_loss: 0.9163\n",
            "Epoch 47/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 297ms/step - accuracy: 0.8619 - loss: 0.9125 - val_accuracy: 0.8736 - val_loss: 0.8721\n",
            "Epoch 48/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.8758 - loss: 0.8665 - val_accuracy: 0.8963 - val_loss: 0.8287\n",
            "Epoch 49/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.8960 - loss: 0.8239 - val_accuracy: 0.9090 - val_loss: 0.7858\n",
            "Epoch 50/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.9102 - loss: 0.7752 - val_accuracy: 0.9292 - val_loss: 0.7437\n",
            "Epoch 51/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.9298 - loss: 0.7420 - val_accuracy: 0.9431 - val_loss: 0.7027\n",
            "Epoch 52/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.9443 - loss: 0.6934 - val_accuracy: 0.9558 - val_loss: 0.6629\n",
            "Epoch 53/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9542 - loss: 0.6625 - val_accuracy: 0.9633 - val_loss: 0.6242\n",
            "Epoch 54/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 295ms/step - accuracy: 0.9653 - loss: 0.6214 - val_accuracy: 0.9722 - val_loss: 0.5867\n",
            "Epoch 55/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 243ms/step - accuracy: 0.9718 - loss: 0.5894 - val_accuracy: 0.9760 - val_loss: 0.5505\n",
            "Epoch 56/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 297ms/step - accuracy: 0.9765 - loss: 0.5525 - val_accuracy: 0.9798 - val_loss: 0.5156\n",
            "Epoch 57/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9800 - loss: 0.5175 - val_accuracy: 0.9861 - val_loss: 0.4822\n",
            "Epoch 58/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 294ms/step - accuracy: 0.9870 - loss: 0.4816 - val_accuracy: 0.9861 - val_loss: 0.4504\n",
            "Epoch 59/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 297ms/step - accuracy: 0.9879 - loss: 0.4529 - val_accuracy: 0.9924 - val_loss: 0.4199\n",
            "Epoch 60/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 243ms/step - accuracy: 0.9905 - loss: 0.4192 - val_accuracy: 0.9987 - val_loss: 0.3909\n",
            "Epoch 61/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - accuracy: 0.9992 - loss: 0.3875 - val_accuracy: 0.9987 - val_loss: 0.3634\n",
            "Epoch 62/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9992 - loss: 0.3630 - val_accuracy: 0.9987 - val_loss: 0.3373\n",
            "Epoch 63/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9992 - loss: 0.3368 - val_accuracy: 1.0000 - val_loss: 0.3128\n",
            "Epoch 64/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 306ms/step - accuracy: 1.0000 - loss: 0.3081 - val_accuracy: 1.0000 - val_loss: 0.2897\n",
            "Epoch 65/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 1.0000 - loss: 0.2897 - val_accuracy: 1.0000 - val_loss: 0.2679\n",
            "Epoch 66/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 1.0000 - loss: 0.2612 - val_accuracy: 1.0000 - val_loss: 0.2475\n",
            "Epoch 67/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 395ms/step - accuracy: 1.0000 - loss: 0.2482 - val_accuracy: 1.0000 - val_loss: 0.2286\n",
            "Epoch 68/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 389ms/step - accuracy: 1.0000 - loss: 0.2254 - val_accuracy: 1.0000 - val_loss: 0.2109\n",
            "Epoch 69/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 408ms/step - accuracy: 1.0000 - loss: 0.2090 - val_accuracy: 1.0000 - val_loss: 0.1945\n",
            "Epoch 70/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 396ms/step - accuracy: 1.0000 - loss: 0.1949 - val_accuracy: 1.0000 - val_loss: 0.1793\n",
            "Epoch 71/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 1.0000 - loss: 0.1777 - val_accuracy: 1.0000 - val_loss: 0.1654\n",
            "Epoch 72/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300ms/step - accuracy: 1.0000 - loss: 0.1649 - val_accuracy: 1.0000 - val_loss: 0.1525\n",
            "Epoch 73/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 0.1530 - val_accuracy: 1.0000 - val_loss: 0.1407\n",
            "Epoch 74/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 242ms/step - accuracy: 1.0000 - loss: 0.1427 - val_accuracy: 1.0000 - val_loss: 0.1298\n",
            "Epoch 75/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240ms/step - accuracy: 1.0000 - loss: 0.1292 - val_accuracy: 1.0000 - val_loss: 0.1200\n",
            "Epoch 76/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 298ms/step - accuracy: 1.0000 - loss: 0.1174 - val_accuracy: 1.0000 - val_loss: 0.1109\n",
            "Epoch 77/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300ms/step - accuracy: 1.0000 - loss: 0.1113 - val_accuracy: 1.0000 - val_loss: 0.1027\n",
            "Epoch 78/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310ms/step - accuracy: 1.0000 - loss: 0.0997 - val_accuracy: 1.0000 - val_loss: 0.0952\n",
            "Epoch 79/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 1.0000 - loss: 0.0941 - val_accuracy: 1.0000 - val_loss: 0.0883\n",
            "Epoch 80/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264ms/step - accuracy: 1.0000 - loss: 0.0880 - val_accuracy: 1.0000 - val_loss: 0.0821\n",
            "Epoch 81/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 1.0000 - loss: 0.0818 - val_accuracy: 1.0000 - val_loss: 0.0763\n",
            "Epoch 82/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 1.0000 - loss: 0.0750 - val_accuracy: 1.0000 - val_loss: 0.0712\n",
            "Epoch 83/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 239ms/step - accuracy: 1.0000 - loss: 0.0712 - val_accuracy: 1.0000 - val_loss: 0.0664\n",
            "Epoch 84/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 319ms/step - accuracy: 1.0000 - loss: 0.0662 - val_accuracy: 1.0000 - val_loss: 0.0622\n",
            "Epoch 85/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296ms/step - accuracy: 1.0000 - loss: 0.0610 - val_accuracy: 1.0000 - val_loss: 0.0583\n",
            "Epoch 86/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 1.0000 - loss: 0.0574 - val_accuracy: 1.0000 - val_loss: 0.0547\n",
            "Epoch 87/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 295ms/step - accuracy: 1.0000 - loss: 0.0552 - val_accuracy: 1.0000 - val_loss: 0.0515\n",
            "Epoch 88/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 0.0508 - val_accuracy: 1.0000 - val_loss: 0.0485\n",
            "Epoch 89/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 392ms/step - accuracy: 1.0000 - loss: 0.0483 - val_accuracy: 1.0000 - val_loss: 0.0458\n",
            "Epoch 90/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 402ms/step - accuracy: 1.0000 - loss: 0.0454 - val_accuracy: 1.0000 - val_loss: 0.0433\n",
            "Epoch 91/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269ms/step - accuracy: 1.0000 - loss: 0.0432 - val_accuracy: 1.0000 - val_loss: 0.0410\n",
            "Epoch 92/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 306ms/step - accuracy: 1.0000 - loss: 0.0412 - val_accuracy: 1.0000 - val_loss: 0.0389\n",
            "Epoch 93/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 1.0000 - loss: 0.0384 - val_accuracy: 1.0000 - val_loss: 0.0370\n",
            "Epoch 94/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 302ms/step - accuracy: 1.0000 - loss: 0.0363 - val_accuracy: 1.0000 - val_loss: 0.0352\n",
            "Epoch 95/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 1.0000 - loss: 0.0345 - val_accuracy: 1.0000 - val_loss: 0.0336\n",
            "Epoch 96/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 238ms/step - accuracy: 1.0000 - loss: 0.0335 - val_accuracy: 1.0000 - val_loss: 0.0321\n",
            "Epoch 97/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 241ms/step - accuracy: 1.0000 - loss: 0.0321 - val_accuracy: 1.0000 - val_loss: 0.0307\n",
            "Epoch 98/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 1.0000 - loss: 0.0305 - val_accuracy: 1.0000 - val_loss: 0.0294\n",
            "Epoch 99/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 238ms/step - accuracy: 1.0000 - loss: 0.0293 - val_accuracy: 1.0000 - val_loss: 0.0282\n",
            "Epoch 100/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 1.0000 - loss: 0.0276 - val_accuracy: 1.0000 - val_loss: 0.0270\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IluDVjDd8OuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference Encoder Model\n",
        "# Example for the encoder model\n",
        "encoder_inputs_inf = layers.Input(shape=(None,))  # Shape (None, ?) for input sequence\n",
        "print(\"Encoder Input Shape: \", encoder_inputs_inf.shape)\n",
        "\n",
        "encoder_embedding_inf = layers.Embedding(input_dim=num_encoder_tokens, output_dim=latent_dim)(encoder_inputs_inf)\n",
        "print(\"Encoder Embedding Shape: \", encoder_embedding_inf.shape)\n",
        "\n",
        "encoder_gru_inf = layers.GRU(latent_dim, return_state=True, return_sequences=True)\n",
        "encoder_outputs_inf, state_h_inf = encoder_gru_inf(encoder_embedding_inf)\n",
        "print(\"Encoder GRU Output Shape: \", encoder_outputs_inf.shape)\n",
        "print(\"Encoder Hidden State Shape: \", state_h_inf.shape)\n",
        "\n",
        "# Create the inference encoder model\n",
        "encoder_model = models.Model(encoder_inputs_inf, [encoder_outputs_inf, state_h_inf])\n",
        "def attention_layer(inputs):\n",
        "    decoder_outputs, encoder_outputs = inputs\n",
        "    attention_scores = layers.Attention()([decoder_outputs, encoder_outputs])  # Attention mechanism\n",
        "    return attention_scores\n",
        "\n",
        "\n",
        "# Inference Decoder Model (after training)\n",
        "# Inference Decoder Model (after training)\n",
        "decoder_state_input_h = layers.Input(shape=(latent_dim,), name='decoder_state_input_h')  # Hidden state from encoder\n",
        "decoder_inputs_inf = layers.Input(shape=(1,), name='decoder_inputs_inf')  # Input token at each timestep\n",
        "# Pass encoder outputs as an input for attention:\n",
        "encoder_outputs_inf_dec = layers.Input(shape=(max_encoder_seq_length, latent_dim), name='encoder_outputs_inf_dec')\n",
        "\n",
        "decoder_embedding_inf = layers.Embedding(input_dim=num_decoder_tokens, output_dim=latent_dim)(decoder_inputs_inf)\n",
        "decoder_gru_inf = layers.GRU(latent_dim, return_sequences=True, return_state=True)\n",
        "\n",
        "# Pass the decoder embedding through the GRU with initial state from encoder\n",
        "decoder_outputs_inf, state_h_inf = decoder_gru_inf(decoder_embedding_inf, initial_state=decoder_state_input_h)\n",
        "\n",
        "# Apply attention mechanism\n",
        "attention_output_inf = attention_layer([decoder_outputs_inf, encoder_outputs_inf_dec]) # Use passed encoder outputs\n",
        "\n",
        "# Concatenate attention output with decoder output\n",
        "context_vector_and_decoder_output_inf = layers.Concatenate(axis=-1)([attention_output_inf, decoder_outputs_inf])\n",
        "\n",
        "# Output layer: Predict next token using softmax activation\n",
        "output_inf = layers.Dense(num_decoder_tokens, activation='softmax')(context_vector_and_decoder_output_inf)\n",
        "\n",
        "# Final Decoder Model: Takes both decoder inputs, decoder state inputs, and encoder outputs for attention\n",
        "decoder_model = models.Model([decoder_inputs_inf, decoder_state_input_h, encoder_outputs_inf_dec], [output_inf, state_h_inf])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OEzKzUms0jR",
        "outputId": "d5692ab2-b71f-4418-9df6-73f04efd5c44"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder Input Shape:  (None, None)\n",
            "Encoder Embedding Shape:  (None, None, 256)\n",
            "Encoder GRU Output Shape:  (None, None, 256)\n",
            "Encoder Hidden State Shape:  (None, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_translation(input_seq):\n",
        "    # Step 1: Encode the input sequence using the encoder model\n",
        "    encoder_outputs_val, state_h_val = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Step 2: Initialize the target sequence with the <start> token\n",
        "    target_seq = np.array([[fr_tokenizer.word_index['<start>']]])\n",
        "\n",
        "    # Step 3: Initialize an empty string to store the translated sentence\n",
        "    translated_sentence = ''\n",
        "\n",
        "    # Step 4: Generate the output sequence token by token\n",
        "    for _ in range(max_decoder_seq_length):\n",
        "        print(f\"target_seq shape: {target_seq.shape}\")  # Should be (1, 1)\n",
        "        print(f\"state_h_val shape: {state_h_val.shape}\")  # Should be (1, 256)\n",
        "\n",
        "        # Predict the next token (French word) from the decoder model\n",
        "        output_tokens, state_h_val = decoder_model.predict(\n",
        "            [target_seq, state_h_val, encoder_outputs_val]\n",
        "        )\n",
        "\n",
        "        # Get the most probable next token\n",
        "        predicted_token = np.argmax(output_tokens[0, -1, :])\n",
        "\n",
        "        # Check if the predicted token is in the index_word dictionary\n",
        "        if predicted_token in fr_tokenizer.index_word:\n",
        "            predicted_word = fr_tokenizer.index_word[predicted_token]\n",
        "        else:\n",
        "            print(f\"Predicted token {predicted_token} is not in index_word dictionary\")\n",
        "            predicted_word = \"<unknown>\"\n",
        "\n",
        "        translated_sentence += ' ' + predicted_word\n",
        "\n",
        "        # Stop if the <end> token is predicted\n",
        "        if predicted_word == '<end>':\n",
        "            break\n",
        "\n",
        "        # Update the target sequence for the next step\n",
        "        target_seq = np.array([[predicted_token]])\n",
        "\n",
        "    return translated_sentence.strip()\n",
        "\n",
        "\n",
        "\n",
        "# Example usage (Translate some English sentences)\n",
        "english_example = \"J'ai froid\"\n",
        "input_seq = eng_tokenizer.texts_to_sequences([english_example])\n",
        "input_seq = pad_sequences(input_seq, maxlen=max_encoder_seq_length, padding='post')\n",
        "\n",
        "print(f\"English: {english_example}\")\n",
        "print(f\"French: {generate_translation(input_seq)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IvRz-D9tCsy",
        "outputId": "1f77c070-1fee-402c-9006-9165bef3db62"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English: J'ai froid\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step\n",
            "target_seq shape: (1, 1)\n",
            "state_h_val shape: (1, 256)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step\n",
            "target_seq shape: (1, 1)\n",
            "state_h_val shape: (1, 256)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "target_seq shape: (1, 1)\n",
            "state_h_val shape: (1, 256)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "target_seq shape: (1, 1)\n",
            "state_h_val shape: (1, 256)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "target_seq shape: (1, 1)\n",
            "state_h_val shape: (1, 256)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "target_seq shape: (1, 1)\n",
            "state_h_val shape: (1, 256)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "target_seq shape: (1, 1)\n",
            "state_h_val shape: (1, 256)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "French: museum museum tired paris paris day paris\n"
          ]
        }
      ]
    }
  ]
}
